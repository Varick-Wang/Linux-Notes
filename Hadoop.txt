DAY04
大数据平台中:

       |--收集数据--搭建分析平台--|
1.需求-|                          |--分析--提交结果
       |--算法--开发(算法)------------|

运维: 收集数据\搭建分析平台\分析\提交结果
                              |---批量操作批量部署
=========================================
大数据:
	互联网累积的各种信息
特性(大数据5V特性):
     数量(Volume)
     速度(Velocity)     
     种类(Variety)
     价值(Value)     
     真实性(Veracity)
=========================================
大数据与Hadoop
Hadoop:
	一种分析和处理海量数据的软件平台
	一款开源软件,使用JAVA开发
	可以提供一个分布式基础架构
Hadoop特点:高可靠性\高扩展性\高效性\高容错性\低成本
++++++++++++++++++++++++++++++++++++++++
Hadoop常用组件(三大核心组件)
	HDFS:Hadoop分布式文件系统(核心组件)
	MapReduce:分布式计算框架(核心组件)
	Yarn:集群资源管理系统(核心组件)
核心组件必须
	Zookeeper:分布式列存储数据库
	......
++++++++++++++++++++++++++++++++++++++++
HDFS角色及概念:
	client:
		--切分文件
		--访问HDFS
		--与NameNode交互,获取文件的位置信息
		--与DateNode交互,读取和写入数据
	block:
		--每块缺省128M大小
		--每块可以多个副本
	DataNode:
		--数据存储节点,存储实际的数据
		--汇报存储信息给NameNode
	NameNode:
		--Master节点,管理HDFS的名称空间和数据映射信息(FSimages),配置副本策略,处理所有客户端请求
	Secondary NameNode
		--定期合并fsimage和fsedits,推送给NameNode
		--紧急情况下,可辅助恢复NameNode
=========================================
MapReduce结构:(开发)(了解)
	Map Task:
	Reduce Task:
	Job Tracker:领导(分配任务)
	Task Tracker:执行人
=========================================		
Yarn结构:Hadoop一个通用的资源管理系统
	
=========================================
hadoop介绍
	部署模式:
	      --单机
	      --伪分布式
	      --完全分布式
++++++++++++++++++++++++++++++++++++++++
单机模式:
	Hadoop安装简单:
	获取软件:http://hadoop.apache.org
	安装配置java环境,安装jps工具
		安装openjdk和openjdk-devel
	设置环境变量,启动运行
	hadoop-env.sh
		export JAVA_HOME="Java安装路径"
		export HADOOP_CONF_DIR="Hadoop配置文件路径"
	单机模式安装简单,只需要配置好环境变量即可运行.这个模式一般用来学习和测试Hadoop的功能
	--测试--统计词频
]#cd /usr/local/hadoop
]#mkdir input
]#cp *.txt  input/
]#./bin/hadoop jar share/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar wordcount input output
=========================================
伪分布式
	伪分布式的安装和完全分布式类似,区别是所有角色安装在一台机器上,使用本地磁盘,一般生产环境都会使用完全分布式,伪分布式一般是用来学习和测试Hadoop的功能
	伪分布式的配置和完全分布式配置类似

Hadoop配置文件及格式
	文件格式
	Hadoop-env.sh
		JAVA_HOME	//通过命令rpm -ql java-1.8.0-openjdk查找
		HADOOP_CONF_DIR	//配置文件位置
	
xml文件配置格式

<property>
    <name></name>
    <value></value>
    <description></description>
</property>


=========================================
HDFS搭建完全分布式
基础环境准备
	4台主机
	禁用selinux
	禁用Firewalld
	配置hosts
	部署ssh-key免密码登录
	安装java-1.8.0-openjdk-devel
=========================================
HDFS完全分布式系统配置
	环境配置文件:	hadoop-env.sh
	核心配置文件:	core-site.xml
	HDFS配置文件:	hdfs-site.xml
	节点配置文件:	slaves
++++++++++++++++++++++++++++++++++++++++
搭建完全分布式:
环境配置文件:	hadoop-env.sh
	OpenJDK的安装目录:JAVA_HOME
	Hadoop配置文件的存放目录:HADOOP_CONF_DIR
++++++++++++++++++++++++++++++++++++++++
核心配置文件:	core-site.xml
	fs.defaultFS:文件系统配置参数
	hadoop.tmp.dir:数据目录配置参数
样式:
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop1</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/var/hadoop</value>
    </property>
++++++++++++++++++++++++++++++++++++++++
HDFS配置文件hdfs-site.xml
	Namenode:地址声明
dfs.namenode.http-address
	Secondarynamenode:地址声明
dfs.namenode.secondary.http-address
	文件冗余份数
dfs.replication

样式:
    <property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop1:50070</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop1:50090</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
++++++++++++++++++++++++++++++++++++++++
节点配置文件:	slaves
	只写DataNode节点的主机名称
	node1
	node2
	node3
	同步配置
	Hadoop所有节点的配置参数完全一样,在一台配置好后,把配置文件同步到其他所有主机上
=========================================
HDFS完全分布式配置 
	在本机(60)创建/var/hadoop
]#mkdir /var/hadoop
	在namenode上执行格式化操作
]#./bin/hdfs namenode -format	//参数可以执行命令查出
	启动集群
]#./sbin/start-dfs.sh
++++++++++++++++++++++++++++++++++++++++
JPS验证角色
NameNode验证
	hadoop]#jps
DataNode验证
	node1]#jps

节点验证:
NameNode上
]#bin/hdfs dfsadmin -report
Configured Capacity: 96602099712 (89.97 GB)
Present Capacity: 89793957888 (83.63 GB)
DFS Remaining: 89793921024 (83.63 GB)
DFS Used: 36864 (36 KB)
DFS Used%: 0.00%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0
Missing blocks (with replication factor 1): 0

-------------------------------------------------
Live datanodes (3):

=========================================
启动DataNode
节点启动中,但是节点信息读不出来
原因分析:
	namenode上/etc/hosts没有配置主机名信息,导致启动了安全模式
解决方案:
	启动datanode,确保服务正常没有问题,与namenode通讯正常
	关闭安全模式,在namenode上
		./bin/hdfs dfsadmin -safemods leave
=========================================
DAY05
	部署原则:资源不冲突(资源互补)
++++++++++++++++++++++++++++++++++++++++
mapred部署
分布式计算框架mapred-site.xml
改名:FROM:mapred-site.xml.template
     TO:mapred-site.xml
资源管理类: mapreduce.framework.name



样式:
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
++++++++++++++++++++++++++++++++++++++++
yarn部署
资源管理yarn-site.xml
	resourcemanager 地址
		yarn.resourcemanager.hostname
	nodemanager 使用哪个计算框架
		yarn.nodemanager.aux-services
	mapreduce_shuffle 计算框架的名称
		mapreduce_shuffle
配置样式:
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>hadoop1</value>
</property>
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
           ***********************
**********配置完成需要同步所有主机***********
           ***********************

启动服务:
	./sbin/start-yarn.sh
	./sbin/start-dfs.sh
验证:
	jps
	./bin/yarn node -list
	
=========================================
web访问Hadoop
	192.168.1.60:50070
	192.168.1.60:50090
	192.168.1.62:50075
	192.168.1.60:8088
	192.168.1.62:8042
=========================================
HDFS基本命令
	]#./bin/hadoop fs			//帮助
	]#./bin/hadoop  fs  -ls
		//对应shell命令
	
	]#./bin/hadoop fs -touchz /abc/dachui	//创建文件
	]#./bin/hadoop  fs -put localfile /remotefile  //上传文件
	]#./bin/hadoop  fs -get  /remotefile	//下载文件
=========================================
Hadoop验证
	创建文件
	上传要分析的文件
	提交分析作业
	查看结果
=========================================
HDFS节点管理(新节点)
HDFS增加新节点:
	启动新的系统,NameNode避ssh密码登录
	修改/etc/hosts
	安装java运行环境(openjdk-devel)
	改NameNode的slaves文件增加节点
	拷贝NameNode的hadoop到本机
	NameNode主机节点上启动DataNode
		]#./sbin/hadoop-daemon.sh start datanode
++++++++++++++++++++++++++++++++++++++++
设置同步带宽,同步数据
	]#./bin/hdfs dfsadmin -setBalancerBandwidth 60000000
	]#./sbin/start-balancer.sh
	查看集群状态:
	]#./bin/hdfs dfsadmin -report
++++++++++++++++++++++++++++++++++++++++
HDFS修复节点

++++++++++++++++++++++++++++++++++++++++
HDFS删除节点
	配置
 
	
++++++++++++++++++++++++++++++++++++++++
yarn节点管理

=========================================
NFS网关
	准备nfs服务器一台(NFSGW:65)
	配置/etc/hosts
	安装java-1.8.0-openjdk-devel
++++++++++++++++++++++++++++++++++++++++
nfsgw , hadoop1添加用户
]#groupadd -g 800 nfsuser
]#useradd -u 800 -g 800 -r -d /var/hadoop nfsuser
++++++++++++++++++++++++++++++++++++++++
hadoop1授权
停止所有服务:
	]#./sbin/stop-all.sh
配置slaves 去掉 newnode
exclude清空:  ]#>/etc/hadoop/exclude
配置core-site.xml
	hadoop.proxyuser.{代理用户}.groups	//挂载点用户所使用的组
	hadoop.proxyuser.{代理用户}.hosts	//挂载点主机ip

样式:
<property>
    <name>hadoop.proxyuser.nfsuser.groups</name>
    <value>*</value>
</property>
<property>
    <name>hadoop.proxyuser.nfsuser.hosts</name>
    <value>*</value>
</property>
++++++++++++++++++++++++++++++++++++++++
同步到其他主机hadoop{2..4}
启动HDFS集群 
	]#./sbin/start-dfs.sh
验证
	]#./bin/hdfs  dfsadmin -report
========================================
配置nfsgw主机
删除冲突应用:
	]# rpm -qa | grep nfs-utils
	]# rpm -qa | grep rpcbind
同步NameNode的Hadoop到nfsgw主机
	]#rsync -av root@hadoop1:/usr/local/hadoop /usr/local/hadoop
++++++++++++++++++++++++++++++++++++++++
nfsgw配置
配置hdfs-site.xml
	nfs.exports.allowed.hosts	//设置访问主机,访问权限(默认只读)
`	nfs.dump.dir	//转存目录

样式:
<property>
    <name>nfs.exports.allowed.hosts</name>
    <value>* rw</value>
</property>
<property>
    <name>nfs.dump.dir</name>
    <value>/var/nfstmp</value>
</property>
++++++++++++++++++++++++++++++++++++++++
配置后创建文件夹/var/nfstmp
	]#mkdir /var/nfstmp
	]#chown nfsuser.nfsuser /var/nfstmp
属组改成代理用户
========================================
NFS启动与挂载
	设置/usr/local/hadoop/logs权限
]#setfacl -m user:nfsuser:rwx /usr/local/hadoop/logs
	使用root启动portmap
]#./sbin/hadoop-daemon.sh --script ./bin/hdfs start portmap
	使用代理用户启动nfs3
]#su -u nfsuser \
	./sbin/hadoop-daemon.sh --script ./bin/hdfs start nfs3
========================================
警告:
	启动portmap需要使用root用户
	启动nfs3需要使用core-site里面设置的代理用户
	必须先启动portmap之后再启动nfs3
	如果portmap重启了,在重启之后nfs3也需要重启
========================================
启动与挂载
	目前NFS只能使用v3版本
	vers=3
	仅使用TCP作为传输协议
	port=tcp
	不支持NLM
	nolock
	禁用access time的时间更新
	noatime
	禁用acl扩展权限
	noacl
++++++++++++++++++++++++++++++++++++++++
启动一台机器并安装nfs-utils
	]#yum -y install nfs-utils
挂载nfs
	]#mount -t nfs -o \
	vers=3,port=tcp,nolock,noatime,noacl\
	192.168.1.65:/  /mnt
========================================
DAY07
========================================
Zookeeper软件
	是一个开源的分布式应用程序协调服务
	用来保证数据在集群间的事务一致性
Zookeeper应用场景
	集群分布式锁
	集群统一命名服务
	分布式协调服务
=========================================
Zookeeper集群的安装配置
	配置文件改名:zoo.cfg
	]#mv zoo_sample.cfg  zoo.cfg
	zoo.cfg文件后添加内容
	server.1=node1:2888:3888
	server.2=node2:2888:3888
	server.3=node3:2888:3888
	server.4=nn01:2888:3888:observer
同步/usr/local/zookeeper到所有机器(每台同步)
启动服务步骤:(每台都有)
	创建文件夹
	]#mkdir /tmp/zookeeper
	创建myid文件
	]#echo 服务器id > /tmp/zookeeper/myid		//服务器ID与myid文件id一致
	启动服务
	]#/usr/local/zookeeper/bin/zkServer.sh start
	]#jps	//查看
=========================================
kafka集群安装与配置
	kafka安装/usr/local/kafka
	配置文件/usr/local/kafka/config/server.properties
	更改内容:
		server.properties
		broker.id
		
		zookeeper.connect
		集群地址写一部分即可(不用不全列出)
启动
	]#/usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties
=========================================
Hadoop高可用
	NameNode高可用:NameNode是HDFS的核心配置,HDFS是Hadoop的核心组件.
=========================================
	冷备
	热备
	双工
=========================================










































	












